{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "import re, yaml\n",
    "from scipy.io.arff import loadarff\n",
    "from scipy.io.arff._arffread import MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move all functions on top\n",
    "# TODO: remove all unnecessary parts that are meant for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data/file65ef3a759daf.arff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_: Path) -> Tuple[pd.DataFrame, MetaData]:\n",
    "    \"\"\"Loads the .arff file (incl. metadata) and converts to utf-8.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    path_ : Path\n",
    "            Path of the data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pd.DataFrame\n",
    "            Data as a dataframe.\n",
    "    meta : scipy.io.arff._arffread.Metadata\n",
    "            Metadata of the dataset.\n",
    "    \"\"\"\n",
    "    # load df and metadata from .arff\n",
    "    data, meta = loadarff(path_)\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    # remove b string from data\n",
    "    str_df = data.select_dtypes([object])\n",
    "    str_df = str_df.stack().str.decode(\"utf-8\").unstack()\n",
    "    data = pd.concat([str_df, data.select_dtypes(exclude=[object])], axis=1)\n",
    "\n",
    "    return data, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, meta = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions of the dataset:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Violation.Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Race\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Color\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"VehicleType\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging categories for feature \"Make\"\n",
    "\n",
    "We observe that in the feature \"Make\" many of the categories in this case car brands/ car manufacturers are misspelled or varying words are used for the same brand. Therefore we need to marge these similar words so that they have the same category.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_variations = {\n",
    "    \"Toyota\": [\"TOYOTA\", \"TOYOTA\", \"TOYTA\", \"TOYT\", \"TOYOYA\", \"TOTY\", \"TOYO\"],\n",
    "    \"Honda\": [\"HONDA\", \"HONNDA\", \"HNDA\", \"HON\", \"HOND\", \"HONDA 4D\"],\n",
    "    \"Hyundai\": [\n",
    "        \"HYUNDAI\",\n",
    "        \"HUNDAI\",\n",
    "        \"HYANDAI\",\n",
    "        \"HUNDAII\",\n",
    "        \"HYUND\",\n",
    "        \"HYUN\",\n",
    "        \"HYUNDIA\",\n",
    "        \"HYUNVA\",\n",
    "        \"HYUANDAI\",\n",
    "        \"HYNDIA\",\n",
    "        \"HYINDAI\",\n",
    "        \"HYUANDAI\",\n",
    "    ],\n",
    "    \"Nissan\": [\n",
    "        \"NISSAN\",\n",
    "        \"NISSON\",\n",
    "        \"NISAN\",\n",
    "        \"NISS\",\n",
    "        \"NISSAB\",\n",
    "        \"NIIS\",\n",
    "        \"NISSAM\",\n",
    "        \"NISSN\",\n",
    "        \"NISSS\",\n",
    "        \"NSSIAN\",\n",
    "        \"NISSVAL1996\",\n",
    "        \"NISSVAL1999\",\n",
    "    ],\n",
    "    \"Ford\": [\"FORD\"],\n",
    "    \"Freightliner\": [\n",
    "        \"FRGHT\",\n",
    "        \"FRHT\",\n",
    "        \"FRIGHTLINER\",\n",
    "        \"FREI\",\n",
    "        \"FREIGHT\",\n",
    "        \"FREIGHTTK\",\n",
    "        \"FREIGHTLINRT\",\n",
    "        \"FREIGHTLINER\",\n",
    "        \"FREIGHTTK\",\n",
    "    ],\n",
    "    \"Mazda\": [\n",
    "        \"MAZDA\",\n",
    "        \"MAZAD\",\n",
    "        \"MAZA\",\n",
    "        \"MADZA\",\n",
    "        \"MAD\",\n",
    "        \"MADZ\",\n",
    "        \"MADZDA\",\n",
    "        \"MAZVA\",\n",
    "        \"MAZVA\",\n",
    "        \"MAZS\",\n",
    "        \"MAZDVAL2010\",\n",
    "        \"MAZDVA\",\n",
    "        \"MADZA\",\n",
    "        \"MAZDVAL2010\",\n",
    "        \"MAZSA\",\n",
    "        \"MAZDA\",\n",
    "        \"MAZDVA\",\n",
    "        \"MAZVAL2010\",\n",
    "        \"MAZDA\",\n",
    "        \"MAZSA\",\n",
    "        \"MAZDA\",\n",
    "        \"MAZDA\",\n",
    "        \"MAZVAL2010\",\n",
    "        \"MAZVA\",\n",
    "        \"MAZVAL2010\",\n",
    "        \"MAZDA\",\n",
    "        \"MAZDVAL2010\",\n",
    "    ],\n",
    "    \"Chrysler\": [\n",
    "        \"CHRYSLER\",\n",
    "        \"CHRY\",\n",
    "        \"CHRSYLER\",\n",
    "        \"CHRYS\",\n",
    "        \"CHYRSLER\",\n",
    "        \"CHRUSLER\",\n",
    "        \"CHY\",\n",
    "        \"CHYR\",\n",
    "        \"CHRYSLTER\",\n",
    "    ],\n",
    "    \"Volkswagen\": [\n",
    "        \"VOLKSWAGEN\",\n",
    "        \"VOLKS\",\n",
    "        \"VW\",\n",
    "        \"VOLK\",\n",
    "        \"VOLKSWAGON\",\n",
    "        \"VOLKVAL2012\",\n",
    "        \"VOLVAL2012\",\n",
    "        \"VOLKS\",\n",
    "        \"VOLKE\",\n",
    "        \"VOLKW\",\n",
    "        \"VOLKSW\",\n",
    "        \"VOLKSWAG\",\n",
    "        \"VOLKSWA\",\n",
    "        \"VOLKSW\",\n",
    "        \"VOLKSWA\",\n",
    "        \"VOLKSWAGGON\",\n",
    "        \"VOLKSWAGONQ\",\n",
    "        \"VOLKSWAGGON\",\n",
    "        \"VWAGON\",\n",
    "        \"VOLK\",\n",
    "        \"VOLVSWAGEN\",\n",
    "        \"VOLKSWAGOM\",\n",
    "        \"VOLKA\",\n",
    "        \"VWOLKS\",\n",
    "        \"VOLKSWAGO\",\n",
    "        \"VOKS\",\n",
    "        \"VOLKS\",\n",
    "        \"VWAGON\",\n",
    "    ],\n",
    "    \"Kia\": [\"KIA\", \"KARA\", \"GENEVAL2003\", \"KYMCO\"],\n",
    "    \"Volvo\": [\"VOLV0\", \"VOLKS\", \"VOLVO\", \"VOLVO TK\", \"VOLVOT\", \"VOLVO SW\"],\n",
    "    \"Chevrolet\": [\n",
    "        \"CHEVROLET\",\n",
    "        \"CHEVEROLET\",\n",
    "        \"CHEV\",\n",
    "        \"CHEVY\",\n",
    "        \"CHEVEROLET\",\n",
    "        \"CEHVY\",\n",
    "        \"CHECROLET\",\n",
    "        \"CHE V\",\n",
    "        \"CHEVOLRET\",\n",
    "        \"CHEVRLET\",\n",
    "        \"CHEVROLETE\",\n",
    "        \"CHEVR\",\n",
    "        \"CHEVROLT\",\n",
    "        \"CHEVROLER\",\n",
    "        \"CHEVROLERT\",\n",
    "        \"CHECEVY\",\n",
    "        \"CHECHY\",\n",
    "        \"CHECY\",\n",
    "        \"CEVEROLET\",\n",
    "        \"CEVY\",\n",
    "        \"CHEVORLET\",\n",
    "        \"CHEVTOLET\",\n",
    "        \"CHEVY GEO\",\n",
    "        \"CHECROLET\",\n",
    "    ],\n",
    "    \"Infiniti\": [\"INFINITI\", \"INFI\", \"INFINIT\", \"INFIITI\", \"INFINIITI\"],\n",
    "    \"Lexus\": [\"LEXUS\", \"LEXS\", \"LEXUS4D\", \"LEXU\", \"LEXSUS\", \"LEVUS\", \"LRXUS\"],\n",
    "    \"Acura\": [\"ACURA\", \"ACUR\", \"ACRUA\", \"ACRURA\", \"ACCORD\", \"ACRURA\"],\n",
    "    \"Dodge\": [\"DODGE\", \"DODGEI\", \"DOSGE\", \"DDGE\"],\n",
    "    \"BMW\": [\"BMW\", \"BWM\", \"BOMW\"],\n",
    "    \"Lincoln\": [\"LINCOLN\", \"LINOLN\", \"LINC\", \"LINCLN\"],\n",
    "    \"Jeep\": [\"JEEP\", \"JEEK\", \"JEEF\", \"JEEPQ\", \"JEE\"],\n",
    "    \"Jaguar\": [\"JAGUAR\", \"JAG\", \"JAGU\"],\n",
    "    \"Porsche\": [\"PORSCHE\", \"PORSCHE\"],\n",
    "    \"Audi\": [\"AUDI\"],\n",
    "    \"Mitsubishi\": [\n",
    "        \"MITSUBISHI\",\n",
    "        \"MITSUBIHI\",\n",
    "        \"MITSUBIHI\",\n",
    "        \"MITS\",\n",
    "        \"MITSUBIHI\",\n",
    "        \"MITSH\",\n",
    "        \"MITSUH\",\n",
    "        \"MITSUBASHI\",\n",
    "        \"MITSU\",\n",
    "        \"MITSUBIHI\",\n",
    "        \"MITSB\",\n",
    "        \"MISTUBISHI\",\n",
    "        \"MISTUBISHI\",\n",
    "        \"MITSUBISH\",\n",
    "        \"MIST\",\n",
    "        \"MITSUBISHU\",\n",
    "        \"MITSUBISH\",\n",
    "        \"MITSUBISI\",\n",
    "    ],\n",
    "    \"Porsche\": [\"PORSCHE\", \"PORSCHE\"],\n",
    "    \"Audi\": [\"AUDI\", \"AUD\"],\n",
    "    \"Mercedes\": [\n",
    "        \"MERCEDES\",\n",
    "        \"MERZ BENZ\",\n",
    "        \"MERCEDEZ\",\n",
    "        \"MERCEDESBENZ\",\n",
    "        \"MERC BENZ\",\n",
    "        \"MERCEDS BENZ\",\n",
    "        \"MERCADES\",\n",
    "        \"MECEDES\",\n",
    "        \"MERCVAL2013\",\n",
    "        \"MERCURY\",\n",
    "        \"MERCER\",\n",
    "        \"MERCZ\",\n",
    "        \"MERZ\",\n",
    "        \"MERK\",\n",
    "        \"MERECEDES\",\n",
    "        \"MERCERY\",\n",
    "        \"MERCADES\",\n",
    "        \"MERCADES\",\n",
    "        \"MERCADES\",\n",
    "        \"MERCADES\",\n",
    "        \"MERCVAL2013\",\n",
    "        \"MERCADES\",\n",
    "        \"MERCERY\",\n",
    "    ],\n",
    "    \"SAAB\": [\"SAAB\", \"SAA\"],\n",
    "    \"Cadillac\": [\"CADILLAC\", \"CADI\", \"CADDI\", \"CADIALLAC\", \"CADDILLAC\"],\n",
    "    \"Lobo\": [\"LOBO\"],\n",
    "    \"Lamborghini\": [\"LAMBORGHINI\", \"LAMBO\"],\n",
    "    \"Subaru\": [\"SUBARU\", \"SUBA\", \"SUBUARU\"],\n",
    "    \"Buick\": [\"BUICK\", \"BRUICK\", \"BUIK\", \"BUK\"],\n",
    "    \"Lotus\": [\"LOTUS\", \"LOTU\"],\n",
    "    \"Rolls Royce\": [\"ROLLS ROYCE\"],\n",
    "    \"Tesla\": [\"TESLA\", \"TESCA\"],\n",
    "    \"Range Rover\": [\"RANGE ROVER\", \"RANG ROVER\", \"RANGEROVER\"],\n",
    "    \"Mini\": [\"MINI\", \"MINN\", \"MNNI\", \"MINICOOP\", \"MINI COOPER\"],\n",
    "    \"Land Rover\": [\"LNDR\"],\n",
    "    \"Plymouth\": [\"PLYMOUTH\", \"PLYM\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yaml(dictionary: dict, yaml_name: str) -> yaml:\n",
    "    \"\"\"creates yaml file from dictionary\n",
    "\n",
    "    Args:\n",
    "        dictionary (dict): the dictionary that is converted\n",
    "        yaml_name (str): the filename of outputed yaml file\n",
    "\n",
    "    Returns:\n",
    "        yaml: the outputed yaml file\n",
    "    \"\"\"\n",
    "    # Convert the dictionary to a YAML string\n",
    "    yaml_string = yaml.dump(dictionary, default_flow_style=False)\n",
    "    # Write the YAML string to a file\n",
    "    with open(\"../config/\" + yaml_name, \"w\") as yaml_file:\n",
    "        yaml_file.write(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yaml(car_variations, \"make_dict.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml(path: Path) -> dict:\n",
    "    \"\"\"Reads yaml file from given path and returns as dict.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    path : Path\n",
    "            Path of the respective yaml file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    make_match_dictionary : dict\n",
    "            Yaml file loaded as dict.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\") as yaml_file:\n",
    "        make_match_dictionary = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "    return make_match_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Make_clean\"] = data[\"Make\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Make_clean\"] = data[\"Make\"]\n",
    "\n",
    "\n",
    "def clean_string(s: str) -> str:\n",
    "    \"\"\"Cleans the string by converting to lowercase and removing alphabetical values.\n",
    "\n",
    "    Args:\n",
    "        s (string): the string that should be changes\n",
    "\n",
    "    Returns:\n",
    "        string: converted string t\n",
    "    \"\"\"\n",
    "    # Remove non-alphanumeric characters and convert to lowercase\n",
    "    s = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", s)\n",
    "    s = s.lower()\n",
    "    return s\n",
    "\n",
    "\n",
    "# Function to find the best match\n",
    "def replace_with_best_match(\n",
    "    df: pd.DataFrame, column_name: str, choices: dict, threshold: int = 50\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Finds best match between value of the dataframe & of dictionary.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame where one column should\n",
    "        be replaced with its best match from the choices dictionary.\n",
    "\n",
    "        column_name (str): The name of column that should be replaced with it's best match\n",
    "        choices (dict):  A dicitionary in which the values\n",
    "        of a row are similar words or choices for matching with the respective value of the column\n",
    "        threshold (int, optional): The threshold set for\n",
    "        the similarity score between the column value and the choices. Defaults to 50.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_best_match(value: str) -> str:\n",
    "        \"\"\"Finds the best match for a given value within the choices.\n",
    "\n",
    "        Args:\n",
    "            value (str): The value to find the best match for.\n",
    "\n",
    "        Returns:\n",
    "            str: The best match for the input value.\n",
    "        \"\"\"\n",
    "        if not value or len(value) < 3:  # Skip empty strings and very short strings\n",
    "            return value, 0\n",
    "\n",
    "        # Clean the input value\n",
    "        value = clean_string(value)\n",
    "        # Clean the choices\n",
    "        cleaned_choices = [clean_string(choice) for choice in choices]\n",
    "\n",
    "        # Use fuzz.token_set_ratio for better token matching\n",
    "        best_match, score = process.extractOne(value, cleaned_choices, scorer=fuzz.token_set_ratio)\n",
    "\n",
    "        if score >= threshold:\n",
    "            best_match = best_match\n",
    "        else:\n",
    "            best_match = value\n",
    "\n",
    "        return best_match\n",
    "\n",
    "    df[column_name] = df[column_name].apply(lambda x: get_best_match(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "replace_with_best_match(data, \"Make_clean\", car_variations)\n",
    "\n",
    "print(data[\"Make_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mapping_hard_coded = {\n",
    "    \"VW\": [\"volkswagen\"],\n",
    "    \"ISU\": [\"isuzu\"],\n",
    "    \"ISUZ\": [\"isuzu\"],\n",
    "    \"MERZ BENZ\": [\"mercedes\"],\n",
    "    \"BENZ\": [\"mercedes\"],\n",
    "    \"MBENZ\": [\"mercedes\"],\n",
    "    \"WV\": [\"volkswagen\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yaml(make_mapping_hard_coded, \"make_dict_hard.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Make_clean\"] = data[\"Make_clean\"].replace(make_mapping_hard_coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_hard(data: pd.DataFrame, dict_hard: dict, column: str = \"Make\") -> pd.DataFrame:\n",
    "    \"\"\"replaces existing categories based on a hard encoded dictionary\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The df that should be changed\n",
    "        dict_hard (dict): The dict that will be used to change the values of a column\n",
    "        column (str, optional): The column that will be changed. Defaults to \"Make\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The df with the changes to a column is returned\n",
    "    \"\"\"\n",
    "    data[column] = data[column].replace(dict_hard)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_top_n(df: pd.DataFrame, column_name: str, n: int) -> pd.DataFrame:\n",
    "    \"\"\"Keep top n classes & missing values and set rest of categories as other.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The df used\n",
    "        column_name (str): The name of the column that should be recategorized\n",
    "        n (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: returns dataframe with limited number of classes\n",
    "    \"\"\"\n",
    "    # get the value counts for the specified column\n",
    "    value_counts = df[column_name].value_counts()\n",
    "\n",
    "    # get top n categories\n",
    "    top_n_categories = value_counts.index[:n].tolist()\n",
    "    top_n_categories.append(\"?\")\n",
    "\n",
    "    # repalce categories not in top n with 'Other'\n",
    "    df[column_name] = df[column_name].apply(lambda x: x if x in top_n_categories else \"Other\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = categorize_top_n(data, \"Make_clean\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "data[\"Make_clean\"].value_counts().head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping color column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_groups = {\n",
    "    \"BLACK\": \"DARK COLORS\",\n",
    "    \"SILVER\": \"LIGHT COLORS\",\n",
    "    \"WHITE\": \"LIGHT COLORS\",\n",
    "    \"GRAY\": \"DARK COLORS\",\n",
    "    \"RED\": \"BOLD COLORS\",\n",
    "    \"BLUE\": \"LIGHT COLORS\",\n",
    "    \"GREEN\": \"BOLD COLORS\",\n",
    "    \"GOLD\": \"BOLD COLORS\",\n",
    "    \"BLUE DARK\": \"DARK COLORS\",\n",
    "    \"TAN\": \"NEUTRAL COLORS\",\n",
    "    \"MAROON\": \"BOLD COLORS\",\n",
    "    \"BLUE LIGHT\": \"LIGHT COLORS\",\n",
    "    \"?\": \"?\",\n",
    "    \"BEIGE\": \"NEUTRAL COLORS\",\n",
    "    \"GREEN DK\": \"BOLD COLORS\",\n",
    "    \"GREEN LGT\": \"BOLD COLORS\",\n",
    "    \"BROWN\": \"NEUTRAL COLORS\",\n",
    "    \"YELLOW\": \"BOLD COLORS\",\n",
    "    \"ORANGE\": \"BOLD COLORS\",\n",
    "    \"BRONZE\": \"BOLD COLORS\",\n",
    "    \"PURPLE\": \"BOLD COLORS\",\n",
    "    \"MULTICOLOR\": \"UNIQUE\",\n",
    "    \"CREAM\": \"UNIQUE\",\n",
    "    \"COPPER\": \"UNIQUE\",\n",
    "    \"PINK\": \"BOLD COLORS\",\n",
    "    \"CHROME\": \"UNIQUE\",\n",
    "    \"CAMOUFLAGE\": \"UNIQUE\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"Color\"] = data[\"Color\"].replace(color_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to fix\n",
    "data = replace_with_hard(data, dict_hard=color_groups, column=\"Color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Color\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping VehicleType column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_type_groups = {\n",
    "    \"02 - Automobile\": \"Standard Vehicles\",\n",
    "    \"03 - Station Wagon\": \"Standard Vehicles\",\n",
    "    \"04 - Limousine\": \"Standard Vehicles\",\n",
    "    \"01 - Motorcycle\": \"Motorcycles and Bikes\",\n",
    "    \"19 - Moped\": \"Motorcycles and Bikes\",\n",
    "    \"26 - Boat Trailer\": \"Motorcycles and Bikes\",\n",
    "    \"05 - Light Duty Truck\": \"Light and Heavy Duty Trucks\",\n",
    "    \"06 - Heavy Duty Truck\": \"Light and Heavy Duty Trucks\",\n",
    "    \"07 - Truck/Road Tractor\": \"Light and Heavy Duty Trucks\",\n",
    "    \"08 - Recreational Vehicle\": \"Special Purpose and Recreational Vehicles\",\n",
    "    \"10 - Transit Bus\": \"Special Purpose and Recreational Vehicles\",\n",
    "    \"12 - School Bus\": \"Special Purpose and Recreational Vehicles\",\n",
    "    \"14 - Ambulance(Non-Emerg)\": \"Special Purpose and Recreational Vehicles\",\n",
    "    \"20 - Commercial Rig\": \"Special Purpose and Recreational Vehicles\",\n",
    "    \"21 - Tandem Trailer\": \"Special Purpose and Recreational Vehicles\",\n",
    "    \"11 - Cross Country Bus\": \"Special Purpose and Recreational Vehicles\",\n",
    "    \"09 - Farm Vehicle\": \"Special Purpose and Recreational Vehicles\",\n",
    "    \"28 - Other\": \"Other\",\n",
    "    \"29 - Unknown\": \"?\",\n",
    "    \"27 - Farm Equipment\": \"Other\",\n",
    "    \"25 - Utility Trailer\": \"Other\",\n",
    "    \"24 - Camper\": \"Other\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = replace_with_hard(data, dict_hard=vehicle_type_groups, column=\"VehicleType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"VehicleType\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
