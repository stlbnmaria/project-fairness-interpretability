{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of refactoring and grouping variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "import re, yaml\n",
    "from scipy.io.arff import loadarff\n",
    "from scipy.io.arff._arffread import MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data/file65ef3a759daf.arff\")\n",
    "CONFIG_HARDCODED = Path(\"..\") / \"config\" / \"dict_hard.yaml\"\n",
    "CONFIG_MAKE = Path(\"..\") / \"config\" / \"dict.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_: Path) -> Tuple[pd.DataFrame, MetaData]:\n",
    "    \"\"\"Loads the .arff file (incl. metadata) and converts to utf-8.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    path_ : Path\n",
    "            Path of the data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pd.DataFrame\n",
    "            Data as a dataframe.\n",
    "    meta : scipy.io.arff._arffread.Metadata\n",
    "            Metadata of the dataset.\n",
    "    \"\"\"\n",
    "    # load df and metadata from .arff\n",
    "    data, meta = loadarff(path_)\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    # remove b string from data\n",
    "    str_df = data.select_dtypes([object])\n",
    "    str_df = str_df.reset_index().melt(id_vars=\"index\").set_index(\"index\")\n",
    "    str_df[\"value\"] = str_df[\"value\"].str.decode(\"utf-8\")\n",
    "\n",
    "    # rename the 'value' column to avoid conflicts and perform pivot\n",
    "    str_df = str_df.rename(columns={\"value\": \"decoded_value\"})\n",
    "    str_df = pd.pivot_table(\n",
    "        str_df, columns=\"variable\", values=\"decoded_value\", index=\"index\", aggfunc=lambda x: x\n",
    "    )\n",
    "\n",
    "    # reset both the column and index names to None\n",
    "    str_df = str_df.rename_axis(index=None, columns=None)\n",
    "\n",
    "    # merge str and non-str columns\n",
    "    data = pd.concat([str_df, data.select_dtypes(exclude=[object])], axis=1)\n",
    "\n",
    "    return data, meta\n",
    "\n",
    "\n",
    "def create_yaml(dictionary: dict, yaml_path: Path, column: str) -> None:\n",
    "    \"\"\"Creates yaml file from dictionary.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    dictionary : dict\n",
    "            Dictionary that is nested and appended.\n",
    "    yaml_path : Path\n",
    "        Path of the output yaml file.\n",
    "    column : str\n",
    "            Column name that is referenced for the mapping.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # created nested dict with column as key\n",
    "    dictionary = {column: dictionary}\n",
    "\n",
    "    # check if file already exists and update the dict inside by appending\n",
    "    if os.path.isfile(yaml_path):\n",
    "        with open(yaml_path, \"r\") as yamlfile:\n",
    "            cur_yaml = yaml.load(yamlfile, Loader=yaml.FullLoader)\n",
    "            cur_yaml.update(dictionary)\n",
    "            dictionary = cur_yaml\n",
    "\n",
    "    # save dict into (new) file\n",
    "    with open(yaml_path, \"w\") as yamlfile:\n",
    "        yaml.safe_dump(dictionary, yamlfile)\n",
    "\n",
    "\n",
    "def read_yaml(path: Path) -> dict:\n",
    "    \"\"\"Reads yaml file from given path and returns as dict.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    path : Path\n",
    "            Path of the respective yaml file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    make_match_dictionary : dict\n",
    "            Yaml file loaded as dict.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\") as yaml_file:\n",
    "        dictionary = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(s: str) -> str:\n",
    "    \"\"\"Cleans the string by converting to lowercase and removing alphabetical values.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    s : str\n",
    "        String that should be changd.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    s : str\n",
    "        Converted string.\n",
    "    \"\"\"\n",
    "    # Remove non-alphanumeric characters and convert to lowercase\n",
    "    s = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", s)\n",
    "    s = s.lower()\n",
    "    return s\n",
    "\n",
    "\n",
    "def get_best_match(value: str, choices: dict, threshold: int = 50) -> str:\n",
    "    \"\"\"Finds the best match for a given value within the choices.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    value : str\n",
    "        The value to find the best match for.\n",
    "    choices : dict\n",
    "        A dicitionary in which the values\n",
    "    choices : dict\n",
    "        A dicitionary in which the values of a row are similar words or\n",
    "        choices for matching with the respective value of the column.\n",
    "    threshold : int\n",
    "        The threshold set for the similarity score between the\n",
    "        column value and the choices. Defaults to 50.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_match : str\n",
    "        The best match for the input value.\n",
    "    \"\"\"\n",
    "    if not value or len(value) < 3:  # Skip empty strings and very short strings\n",
    "        return value\n",
    "\n",
    "    # Clean the input value\n",
    "    value = clean_string(value)\n",
    "    # Clean the choices\n",
    "    cleaned_choices = [clean_string(choice) for choice in choices]\n",
    "\n",
    "    # Use fuzz.token_set_ratio for better token matching\n",
    "    best_match, score = process.extractOne(value, cleaned_choices, scorer=fuzz.token_set_ratio)\n",
    "\n",
    "    if score >= threshold:\n",
    "        best_match = best_match\n",
    "    else:\n",
    "        best_match = value\n",
    "\n",
    "    return best_match\n",
    "\n",
    "\n",
    "# Function to find the best match\n",
    "def replace_with_best_match(\n",
    "    df: pd.DataFrame, column_name: str, choices: dict, threshold: int = 50\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Finds best match between value of the dataframe & of dictionary.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        The input DataFrame where one column should.\n",
    "    column_name : str\n",
    "        The name of column that should be replaced with it's best match.\n",
    "    choices : dict\n",
    "        A dicitionary in which the values of a row are similar words or\n",
    "        choices for matching with the respective value of the column.\n",
    "    threshold : int\n",
    "        The threshold set for the similarity score between the\n",
    "        column value and the choices. Defaults to 50.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pd.DataFrame\n",
    "        Transofrmed dataframe.\n",
    "    \"\"\"\n",
    "    df[column_name] = df[column_name].apply(lambda x: get_best_match(x, choices, threshold))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_hard(data: pd.DataFrame, dict_hard: dict, column: str) -> pd.DataFrame:\n",
    "    \"\"\"Replaces existing categories based on a hard encoded dictionary.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    data : pd.DataFrame\n",
    "        Dataframe to transform.\n",
    "    dict_hard : dict\n",
    "        Dict that will be used to change the values of a column.\n",
    "    column : str\n",
    "        The column that will be changed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pd.DataFrame\n",
    "        Transofrmed dataframe.\n",
    "    \"\"\"\n",
    "    inv_map = {val: k for k, v in dict_hard.items() for val in v}\n",
    "    data[column] = data[column].replace(inv_map)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_top_n(df: pd.DataFrame, column_name: str, n: int) -> pd.DataFrame:\n",
    "    \"\"\"Keep top n classes & missing values and set rest of categories as other.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The df used\n",
    "        column_name (str): The name of the column that should be recategorized\n",
    "        n (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: returns dataframe with limited number of classes\n",
    "    \"\"\"\n",
    "    # get the value counts for the specified column\n",
    "    value_counts = df[column_name].value_counts()\n",
    "\n",
    "    # get top n categories\n",
    "    top_n_categories = value_counts.index[:n].tolist()\n",
    "    top_n_categories.append(\"?\")\n",
    "\n",
    "    # repalce categories not in top n with 'Other'\n",
    "    df[column_name] = df[column_name].apply(lambda x: x if x in top_n_categories else \"other\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, meta = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Make\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Color\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"VehicleType\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging categories for feature \"Make\"\n",
    "\n",
    "We observe that in the feature \"Make\" many of the categories in this case car brands/ car manufacturers are misspelled or varying words are used for the same brand. Therefore we need to marge these similar words so that they have the same category.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_variations = {\n",
    "    \"Toyota\": [\"TOYOTA\", \"TOYOTA\", \"TOYTA\", \"TOYT\", \"TOYOYA\", \"TOTY\", \"TOYO\"],\n",
    "    \"Honda\": [\"HONDA\", \"HONNDA\", \"HNDA\", \"HON\", \"HOND\", \"HONDA 4D\"],\n",
    "    \"Hyundai\": [\n",
    "        \"HYUNDAI\",\n",
    "        \"HUNDAI\",\n",
    "        \"HYANDAI\",\n",
    "        \"HUNDAII\",\n",
    "        \"HYUND\",\n",
    "        \"HYUN\",\n",
    "        \"HYUNDIA\",\n",
    "        \"HYUNVA\",\n",
    "        \"HYUANDAI\",\n",
    "        \"HYNDIA\",\n",
    "        \"HYINDAI\",\n",
    "        \"HYUANDAI\",\n",
    "    ],\n",
    "    \"Nissan\": [\n",
    "        \"NISSAN\",\n",
    "        \"NISSON\",\n",
    "        \"NISAN\",\n",
    "        \"NISS\",\n",
    "        \"NISSAB\",\n",
    "        \"NIIS\",\n",
    "        \"NISSAM\",\n",
    "        \"NISSN\",\n",
    "        \"NISSS\",\n",
    "        \"NSSIAN\",\n",
    "        \"NISSVAL1996\",\n",
    "        \"NISSVAL1999\",\n",
    "    ],\n",
    "    \"Ford\": [\"FORD\"],\n",
    "    \"Freightliner\": [\n",
    "        \"FRGHT\",\n",
    "        \"FRHT\",\n",
    "        \"FRIGHTLINER\",\n",
    "        \"FREI\",\n",
    "        \"FREIGHT\",\n",
    "        \"FREIGHTTK\",\n",
    "        \"FREIGHTLINRT\",\n",
    "        \"FREIGHTLINER\",\n",
    "        \"FREIGHTTK\",\n",
    "    ],\n",
    "    \"Mazda\": [\n",
    "        \"MAZDA\",\n",
    "        \"MAZAD\",\n",
    "        \"MAZA\",\n",
    "        \"MADZA\",\n",
    "        \"MAD\",\n",
    "        \"MADZ\",\n",
    "        \"MADZDA\",\n",
    "        \"MAZVA\",\n",
    "        \"MAZVA\",\n",
    "        \"MAZS\",\n",
    "        \"MAZDVAL2010\",\n",
    "        \"MAZDVA\",\n",
    "        \"MADZA\",\n",
    "        \"MAZDVAL2010\",\n",
    "        \"MAZSA\",\n",
    "        \"MAZDA\",\n",
    "        \"MAZDVA\",\n",
    "        \"MAZVAL2010\",\n",
    "        \"MAZDA\",\n",
    "        \"MAZSA\",\n",
    "        \"MAZDA\",\n",
    "        \"MAZDA\",\n",
    "        \"MAZVAL2010\",\n",
    "        \"MAZVA\",\n",
    "        \"MAZVAL2010\",\n",
    "        \"MAZDA\",\n",
    "        \"MAZDVAL2010\",\n",
    "    ],\n",
    "    \"Chrysler\": [\n",
    "        \"CHRYSLER\",\n",
    "        \"CHRY\",\n",
    "        \"CHRSYLER\",\n",
    "        \"CHRYS\",\n",
    "        \"CHYRSLER\",\n",
    "        \"CHRUSLER\",\n",
    "        \"CHY\",\n",
    "        \"CHYR\",\n",
    "        \"CHRYSLTER\",\n",
    "    ],\n",
    "    \"Volkswagen\": [\n",
    "        \"VOLKSWAGEN\",\n",
    "        \"VOLKS\",\n",
    "        \"VW\",\n",
    "        \"VOLK\",\n",
    "        \"VOLKSWAGON\",\n",
    "        \"VOLKVAL2012\",\n",
    "        \"VOLVAL2012\",\n",
    "        \"VOLKS\",\n",
    "        \"VOLKE\",\n",
    "        \"VOLKW\",\n",
    "        \"VOLKSW\",\n",
    "        \"VOLKSWAG\",\n",
    "        \"VOLKSWA\",\n",
    "        \"VOLKSW\",\n",
    "        \"VOLKSWA\",\n",
    "        \"VOLKSWAGGON\",\n",
    "        \"VOLKSWAGONQ\",\n",
    "        \"VOLKSWAGGON\",\n",
    "        \"VWAGON\",\n",
    "        \"VOLK\",\n",
    "        \"VOLVSWAGEN\",\n",
    "        \"VOLKSWAGOM\",\n",
    "        \"VOLKA\",\n",
    "        \"VWOLKS\",\n",
    "        \"VOLKSWAGO\",\n",
    "        \"VOKS\",\n",
    "        \"VOLKS\",\n",
    "        \"VWAGON\",\n",
    "    ],\n",
    "    \"Kia\": [\"KIA\", \"KARA\", \"GENEVAL2003\", \"KYMCO\"],\n",
    "    \"Volvo\": [\"VOLV0\", \"VOLKS\", \"VOLVO\", \"VOLVO TK\", \"VOLVOT\", \"VOLVO SW\"],\n",
    "    \"Chevrolet\": [\n",
    "        \"CHEVROLET\",\n",
    "        \"CHEVEROLET\",\n",
    "        \"CHEV\",\n",
    "        \"CHEVY\",\n",
    "        \"CHEVEROLET\",\n",
    "        \"CEHVY\",\n",
    "        \"CHECROLET\",\n",
    "        \"CHE V\",\n",
    "        \"CHEVOLRET\",\n",
    "        \"CHEVRLET\",\n",
    "        \"CHEVROLETE\",\n",
    "        \"CHEVR\",\n",
    "        \"CHEVROLT\",\n",
    "        \"CHEVROLER\",\n",
    "        \"CHEVROLERT\",\n",
    "        \"CHECEVY\",\n",
    "        \"CHECHY\",\n",
    "        \"CHECY\",\n",
    "        \"CEVEROLET\",\n",
    "        \"CEVY\",\n",
    "        \"CHEVORLET\",\n",
    "        \"CHEVTOLET\",\n",
    "        \"CHEVY GEO\",\n",
    "        \"CHECROLET\",\n",
    "    ],\n",
    "    \"Infiniti\": [\"INFINITI\", \"INFI\", \"INFINIT\", \"INFIITI\", \"INFINIITI\"],\n",
    "    \"Lexus\": [\"LEXUS\", \"LEXS\", \"LEXUS4D\", \"LEXU\", \"LEXSUS\", \"LEVUS\", \"LRXUS\"],\n",
    "    \"Acura\": [\"ACURA\", \"ACUR\", \"ACRUA\", \"ACRURA\", \"ACCORD\", \"ACRURA\"],\n",
    "    \"Dodge\": [\"DODGE\", \"DODGEI\", \"DOSGE\", \"DDGE\"],\n",
    "    \"BMW\": [\"BMW\", \"BWM\", \"BOMW\"],\n",
    "    \"Lincoln\": [\"LINCOLN\", \"LINOLN\", \"LINC\", \"LINCLN\"],\n",
    "    \"Jeep\": [\"JEEP\", \"JEEK\", \"JEEF\", \"JEEPQ\", \"JEE\"],\n",
    "    \"Jaguar\": [\"JAGUAR\", \"JAG\", \"JAGU\"],\n",
    "    \"Porsche\": [\"PORSCHE\", \"PORSCHE\"],\n",
    "    \"Audi\": [\"AUDI\"],\n",
    "    \"Mitsubishi\": [\n",
    "        \"MITSUBISHI\",\n",
    "        \"MITSUBIHI\",\n",
    "        \"MITSUBIHI\",\n",
    "        \"MITS\",\n",
    "        \"MITSUBIHI\",\n",
    "        \"MITSH\",\n",
    "        \"MITSUH\",\n",
    "        \"MITSUBASHI\",\n",
    "        \"MITSU\",\n",
    "        \"MITSUBIHI\",\n",
    "        \"MITSB\",\n",
    "        \"MISTUBISHI\",\n",
    "        \"MISTUBISHI\",\n",
    "        \"MITSUBISH\",\n",
    "        \"MIST\",\n",
    "        \"MITSUBISHU\",\n",
    "        \"MITSUBISH\",\n",
    "        \"MITSUBISI\",\n",
    "    ],\n",
    "    \"Porsche\": [\"PORSCHE\", \"PORSCHE\"],\n",
    "    \"Audi\": [\"AUDI\", \"AUD\"],\n",
    "    \"Mercedes\": [\n",
    "        \"MERCEDES\",\n",
    "        \"MERZ BENZ\",\n",
    "        \"MERCEDEZ\",\n",
    "        \"MERCEDESBENZ\",\n",
    "        \"MERC BENZ\",\n",
    "        \"MERCEDS BENZ\",\n",
    "        \"MERCADES\",\n",
    "        \"MECEDES\",\n",
    "        \"MERCVAL2013\",\n",
    "        \"MERCURY\",\n",
    "        \"MERCER\",\n",
    "        \"MERCZ\",\n",
    "        \"MERZ\",\n",
    "        \"MERK\",\n",
    "        \"MERECEDES\",\n",
    "        \"MERCERY\",\n",
    "        \"MERCADES\",\n",
    "        \"MERCADES\",\n",
    "        \"MERCADES\",\n",
    "        \"MERCADES\",\n",
    "        \"MERCVAL2013\",\n",
    "        \"MERCADES\",\n",
    "        \"MERCERY\",\n",
    "    ],\n",
    "    \"SAAB\": [\"SAAB\", \"SAA\"],\n",
    "    \"Cadillac\": [\"CADILLAC\", \"CADI\", \"CADDI\", \"CADIALLAC\", \"CADDILLAC\"],\n",
    "    \"Lobo\": [\"LOBO\"],\n",
    "    \"Lamborghini\": [\"LAMBORGHINI\", \"LAMBO\"],\n",
    "    \"Subaru\": [\"SUBARU\", \"SUBA\", \"SUBUARU\"],\n",
    "    \"Buick\": [\"BUICK\", \"BRUICK\", \"BUIK\", \"BUK\"],\n",
    "    \"Lotus\": [\"LOTUS\", \"LOTU\"],\n",
    "    \"Rolls Royce\": [\"ROLLS ROYCE\"],\n",
    "    \"Tesla\": [\"TESLA\", \"TESCA\"],\n",
    "    \"Range Rover\": [\"RANGE ROVER\", \"RANG ROVER\", \"RANGEROVER\"],\n",
    "    \"Mini\": [\"MINI\", \"MINN\", \"MNNI\", \"MINICOOP\", \"MINI COOPER\"],\n",
    "    \"Land Rover\": [\"LNDR\"],\n",
    "    \"Plymouth\": [\"PLYMOUTH\", \"PLYM\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yaml(car_variations, CONFIG_MAKE, \"Make\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Make_clean\"] = data[\"Make\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_with_best_match(data, \"Make_clean\", car_variations)\n",
    "\n",
    "print(data[\"Make_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mapping_hard_coded = {\n",
    "    \"mercedes\": [\"MERZ BENZ\", \"BENZ\", \"MBENZ\"],\n",
    "    \"isuzu\": [\"ISU\", \"ISUZ\"],\n",
    "    \"volkswagen\": [\"VW\", \"WV\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yaml(make_mapping_hard_coded, CONFIG_HARDCODED, \"Make\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = replace_with_hard(data, dict_hard=make_mapping_hard_coded, column=\"Make_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Make_clean\"].value_counts().head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = categorize_top_n(data, \"Make_clean\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Make_clean\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping color column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_groups = {\n",
    "    \"DARK COLORS\": [\"BLACK\", \"GRAY\", \"BLUE DARK\", \"GREEN DK\", \"BROWN\"],\n",
    "    \"LIGHT COLORS\": [\"SILVER\", \"WHITE\", \"BLUE LIGHT\", \"TAN\", \"BEIGE\", \"CREAM\"],\n",
    "    \"BOLD COLORS\": [\n",
    "        \"RED\",\n",
    "        \"MAROON\",\n",
    "        \"GREEN\",\n",
    "        \"GOLD\",\n",
    "        \"BLUE\",\n",
    "        \"GREEN LGT\",\n",
    "        \"YELLOW\",\n",
    "        \"ORANGE\",\n",
    "        \"BRONZE\",\n",
    "        \"PURPLE\",\n",
    "        \"MULTICOLOR\",\n",
    "        \"PINK\",\n",
    "        \"COPPER\",\n",
    "        \"CHROME\",\n",
    "        \"CAMOUFLAGE\",\n",
    "    ],\n",
    "    \"?\": [\"?\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yaml(color_groups, CONFIG_HARDCODED, \"Color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = replace_with_hard(data, dict_hard=color_groups, column=\"Color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Color\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping VehicleType column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_type_groups = {\n",
    "    \"Standard Vehicles\": [\"02 - Automobile\", \"03 - Station Wagon\", \"04 - Limousine\"],\n",
    "    \"Motorcycles\": [\"01 - Motorcycle\", \"19 - Moped\"],\n",
    "    \"Trucks\": [\n",
    "        \"05 - Light Duty Truck\",\n",
    "        \"06 - Heavy Duty Truck\",\n",
    "        \"20 - Commercial Rig\",\n",
    "    ],\n",
    "    \"Special Purpose\": [\n",
    "        \"21 - Tandem Trailer\",\n",
    "        \"25 - Utility Trailer\",\n",
    "        \"09 - Farm Vehicle\",\n",
    "        \"07 - Truck/Road Tractor\",\n",
    "        \"27 - Farm Equipment\",\n",
    "        \"10 - Transit Bus\",\n",
    "        \"12 - School Bus\",\n",
    "        \"11 - Cross Country Bus\",\n",
    "        \"14 - Ambulance(Non-Emerg)\",\n",
    "    ],\n",
    "    \"other\": [\"28 - Other\", \"24 - Camper\", \"26 - Boat Trailer\", \"08 - Recreational Vehicle\"],\n",
    "    \"?\": [\"29 - Unknown\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yaml(vehicle_type_groups, CONFIG_HARDCODED, \"VehicleType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = replace_with_hard(data, dict_hard=vehicle_type_groups, column=\"VehicleType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"VehicleType\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
